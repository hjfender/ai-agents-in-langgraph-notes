{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can find more prompt templates here: https://smith.langchain.com/hub/hwchase17/react"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of the agentic frameworks from research papers could be represented as DAGs with:\n",
    "- nodes: agents or functions\n",
    "- edges: connect nodes\n",
    "- conditional edges: decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data/State is important in LangGraph\n",
    "- it is accessible to all parts of the graph\n",
    "- local to the graph\n",
    "- can be stored in a persistence layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent LangGraph Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used to graph\n",
    "from langgraph.graph import StateGraph, END\n",
    "# used to construct agent state\n",
    "from typing import TypedDict, Annotated \n",
    "import operator\n",
    "# message types to represent human and ai messages\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "# standard interface in LangChain - can swap language models easily\n",
    "from langchain_openai import ChatOpenAI\n",
    "# tavily search engine for tool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_community.tools.tavily_search.tool.TavilySearchResults'>\n",
      "tavily_search_results_json\n"
     ]
    }
   ],
   "source": [
    "tool = TavilySearchResults(max_results=2)\n",
    "print(type(tool))\n",
    "print(tool.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, model, tools, system=\"\"):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_openai)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_conditional_edges(\n",
    "            \"llm\",\n",
    "            self.exists_action,\n",
    "            {True: \"action\", False: END} # Routing logic\n",
    "        )\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        # Turn the graph into a lang chain runnable\n",
    "        self.graph = graph.compile()\n",
    "        self.tools = { t.name: t for t in tools }\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def exists_action(self, state: AgentState):\n",
    "        result = state[\"messages\"][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    def call_openai(self, state: AgentState):\n",
    "        messages = state[\"messages\"]\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        # because we annotated the type the following does not override \"messages\"\n",
    "        # but adds to it\n",
    "        return { \"messages\": [message] }\n",
    "    \n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls = state[\"messages\"][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "            result = self.tools[t[\"name\"]].invoke(t[\"args\"])\n",
    "            results.append(ToolMessage(tool_call_id=t[\"id\"], name=t[\"name\"], content=str(result)))\n",
    "        print(\"Back to the model\")\n",
    "        return { \"messages\": results }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "abot = Agent(model, [tool], system=prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "# Image(abot.graph.get_graph().draw_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'weather in San Francisco'}, 'id': 'call_ufoLDwMhNA4PDhyP9vLp3iBT'}\n",
      "Back to the model\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in sf?\")]\n",
    "result = abot.graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is the weather in sf?'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_ufoLDwMhNA4PDhyP9vLp3iBT', 'function': {'arguments': '{\"query\":\"weather in San Francisco\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 153, 'total_tokens': 175, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-01c8d7d2-b989-4d34-b020-b4ee75b63bd9-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in San Francisco'}, 'id': 'call_ufoLDwMhNA4PDhyP9vLp3iBT'}]),\n",
       "  ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.775, \\'lon\\': -122.4183, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1740805715, \\'localtime\\': \\'2025-02-28 21:08\\'}, \\'current\\': {\\'last_updated_epoch\\': 1740805200, \\'last_updated\\': \\'2025-02-28 21:00\\', \\'temp_c\\': 13.3, \\'temp_f\\': 55.9, \\'is_day\\': 0, \\'condition\\': {\\'text\\': \\'Partly cloudy\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/night/116.png\\', \\'code\\': 1003}, \\'wind_mph\\': 5.4, \\'wind_kph\\': 8.6, \\'wind_degree\\': 239, \\'wind_dir\\': \\'WSW\\', \\'pressure_mb\\': 1014.0, \\'pressure_in\\': 29.93, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 90, \\'cloud\\': 75, \\'feelslike_c\\': 12.8, \\'feelslike_f\\': 55.0, \\'windchill_c\\': 9.6, \\'windchill_f\\': 49.3, \\'heatindex_c\\': 10.4, \\'heatindex_f\\': 50.8, \\'dewpoint_c\\': 9.7, \\'dewpoint_f\\': 49.5, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 0.0, \\'gust_mph\\': 9.7, \\'gust_kph\\': 15.6}}\"}, {\\'url\\': \\'https://world-weather.info/forecast/usa/san_francisco/march-2025/\\', \\'content\\': \"Weather in San Francisco in March 2025 (California) - Detailed Weather Forecast for a Month Weather in San Francisco Weather in San Francisco in March 2025 San Francisco Weather Forecast for March 2025 is based on long term prognosis and previous years\\' statistical data. 1 +54°+52° 2 +54°+50° 3 +54°+50° 4 +54°+48° 5 +61°+46° +59°+50° +59°+50° +61°+50° +61°+52° +61°+52° +63°+52° +63°+52° +61°+52° +61°+52° +63°+54° +61°+52° +63°+50° +61°+52° +61°+52° +59°+52° +61°+52° +59°+50° +57°+50° +57°+50° +59°+50° +59°+50° +61°+52° +63°+52° +63°+54° +63°+52° +63°+54° Extended weather forecast in San Francisco HourlyWeek10-Day14-Day30-DayYear Weather in Washington, D.C.+32° Sacramento+55° Pleasanton+52° Redwood City+55° San Leandro+55° San Mateo+54° San Rafael+55° San Ramon+52° South San Francisco+54° Vallejo+54° Palo Alto+55° Pacifica+55° Berkeley+57° Castro Valley+54° Concord+54° Daly City+54° Lagunitas+55° world\\'s temperature today day day Temperature units\"}]', name='tavily_search_results_json', tool_call_id='call_ufoLDwMhNA4PDhyP9vLp3iBT'),\n",
       "  AIMessage(content='The current weather in San Francisco is partly cloudy with a temperature of 55.9°F (13.3°C). The wind speed is 5.4 mph (8.6 kph) coming from the west-southwest direction. The humidity is at 90%, and the visibility is 9.0 miles.', response_metadata={'token_usage': {'completion_tokens': 68, 'prompt_tokens': 994, 'total_tokens': 1062, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-0cc23659-071c-43ff-8427-6fce2e538298-0')]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current weather in San Francisco is partly cloudy with a temperature of 55.9°F (13.3°C). The wind speed is 5.4 mph (8.6 kph) coming from the west-southwest direction. The humidity is at 90%, and the visibility is 9.0 miles.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'weather in San Francisco'}, 'id': 'call_ZzWaCtrtNXZS4ecGn5Oahz6j'}\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'weather in Los Angeles'}, 'id': 'call_qall2KAo3h4eascx6hVY1eu3'}\n",
      "Back to the model\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in SF and LA?\")]\n",
    "result = abot.graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current weather in San Francisco is partly cloudy with a temperature of 55.9°F (13.3°C). The wind speed is 5.4 mph and the humidity is at 90%.\n",
      "\n",
      "In Los Angeles, the current weather is also partly cloudy with a temperature of 57.0°F (13.9°C). The wind speed is 4.3 mph and the humidity is at 77%.\n"
     ]
    }
   ],
   "source": [
    "print(result['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'Super Bowl 2024 winner'}, 'id': 'call_rnqf4gaGDfEDlSnkEKaq7MC9'}\n",
      "Back to the model\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'Kansas City Chiefs headquarters location'}, 'id': 'call_2pr8R39EWcJKtKzp1dse3LDY'}\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'Missouri GDP 2024'}, 'id': 'call_VAgGjjutJRUchGjrcgt30bRr'}\n",
      "Back to the model\n"
     ]
    }
   ],
   "source": [
    "query = \"Who won the super bowl in 2024? In what state is the winning team headquarters located? \\\n",
    "What is the GDP of that state? Answer each question.\" \n",
    "messages = [HumanMessage(content=query)]\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\")  # requires more advanced model\n",
    "abot = Agent(model, [tool], system=prompt)\n",
    "result = abot.graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The Kansas City Chiefs won the Super Bowl in 2024.\n",
      "\n",
      "2. The headquarters of the Kansas City Chiefs is located in Kansas City, Missouri.\n",
      "\n",
      "3. As of 2023, the GDP of Missouri was $348.5 billion.\n"
     ]
    }
   ],
   "source": [
    "print(result['messages'][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-agents-in-langgraph-notes-ufgr41S4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
